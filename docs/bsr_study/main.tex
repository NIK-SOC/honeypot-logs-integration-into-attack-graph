\documentclass[conference]{IEEEtran}

\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{hyperref}

\begin{document}

\title{Integration of Honeypot Logs into Neo4j Graph Database Using the STIX Data Model}

\author{\IEEEauthorblockN{1\textsuperscript{st} Sándor Róbert Bakos}
\IEEEauthorblockA{\textit{John von Neumann Faculty of Informatics} \\
\textit{Obuda University}\\
Budapest, Hungary \\
sandor.r.bakos@stud.uni-obuda.hu}
}

\maketitle

\begin{abstract}
This paper aims to demonstrate the integration of honeypot logs into a Neo4j graph database using the STIX data model. The study focuses on creating and analyzing attack graphs for identifying vulnerabilities and attack patterns while exploring their applicability in optimizing Security Operation Centers (SOC).
\end{abstract}

\begin{IEEEkeywords}
honeypot, STIX, attack graph, Neo4j, SOC
\end{IEEEkeywords}

\thanks{This document was partially written with the assistance of ChatGPT, an AI language model developed by OpenAI.\cite{openai2024chatgpt}}

\section{Introduction}

In the rapidly evolving landscape of cybersecurity, the ability to detect, analyze, and mitigate threats is paramount for maintaining secure systems. Cyber attackers continuously develop sophisticated methods to exploit vulnerabilities, necessitating proactive defense mechanisms~\cite{mirkovic2004taxonomy}. Honeypots, which are decoy systems designed to attract attackers, generate vast amounts of data that provide valuable insights into malicious activities~\cite{spitzner2003honeypots, provos2007virtual}. By simulating vulnerable systems, honeypots capture detailed information about attack vectors, tools, and methodologies employed by adversaries. However, analyzing these logs in their raw form presents significant challenges due to their volume, complexity, and lack of standardization~\cite{katti2018honeypot}.

Traditional data analysis techniques may not efficiently handle the complex relationships inherent in cybersecurity data. Graph databases, such as Neo4j, offer powerful means to model and analyze these relationships effectively~\cite{robinson2015graph}. Furthermore, the Structured Threat Information Expression (STIX) data model provides a standardized framework for representing cyber threat intelligence, facilitating information sharing and interoperability~\cite{oasis2023stix}.

This paper aims to demonstrate the integration of honeypot logs into a Neo4j graph database using the STIX data model. By leveraging Neo4j's graph capabilities and STIX's structured approach to threat intelligence, this study seeks to create and analyze attack graphs to identify vulnerabilities, track attack paths, and derive actionable insights. This integration enables the visualization of complex attack patterns and supports more effective threat analysis and response.

The novelty of this research lies in its focus on applying a graph-based approach to honeypot log analysis within the STIX framework. While previous studies have explored honeypot data analysis and the use of graph databases separately, the combined application in this context is less explored~\cite{sharma2018utilizing}. This approach not only enhances the visualization of attack patterns but also facilitates better decision-making in Security Operations Centers (SOCs) by providing a comprehensive view of threats~\cite{ring2019survey}. Additionally, it offers a scalable and standardized method for transforming and integrating threat intelligence data, promoting collaboration across organizations~\cite{barnum2012standardizing}.

The remainder of this paper is structured as follows: \textbf{Section 2} provides background on honeypots, the STIX data model, and Neo4j. \textbf{Section 3} describes the methodology for integrating honeypot logs into a graph database. \textbf{Section 4} presents the key findings and directions for future work.




\section{Background}
\subsection{Honeypot Technology}
Honeypots are designed to gather intelligence on attack methods and deceive attackers. They have been widely used in SOC environments for monitoring and profiling adversarial behavior \cite{honeypotsurvey}.

\subsection{STIX Data Model}
The Structured Threat Information Expression (STIX) data model provides a standardized approach for representing and sharing cyber threat intelligence. STIX objects, such as domain objects (e.g., attack patterns, vulnerabilities) and relationships (e.g., "targets" or "uses"), form the building blocks of structured cyber threat data \cite{simonnagy2022attackgraphs}.


\subsection{Neo4j Graph Database}
Neo4j's Labeled Property Graph (LPG) model is highly suited for representing STIX data due to its ability to handle nodes and relationships with properties efficiently. The use of Cypher, Neo4j’s query language, enables fast traversal and pattern matching, making it ideal for analyzing complex attack graphs \cite{simonnagy2022attackgraphs}.


\subsection{Attack Graphs}
Attack graphs represent vulnerabilities and potential attack paths in a system. They are commonly used in SOCs to enhance risk assessment and prioritize security measures \cite{attackgraphsurvey}.

\section{Methodology}
\subsection{Synthetic Honeypot Log Generation}

To demonstrate the integration of honeypot logs into a Neo4j graph database using the STIX data model, we developed a Python script to generate synthetic honeypot logs. This approach allowed us to create controlled datasets that mimic real-world cyber-attack patterns while avoiding the ethical and legal implications of using real attack data~\cite{provos2007virtual}.

\subsubsection{Methodology}

We designed a Python script that generates synthetic honeypot logs with the following key features:

\begin{enumerate}
    \item \textbf{Attack Simulation with Logical Dependencies}: The script simulates common cyber attacks by randomly selecting attack types such as SSH brute-force, SQL injection, and DDoS attacks. Each attack type is logically linked to appropriate target services:
    \begin{itemize}
        \item \textbf{SSH brute-force} targets services like SSH.
        \item \textbf{SQL injection} attacks target database services such as MySQL or PostgreSQL.
        \item \textbf{DDoS} attacks target services like HTTP or DNS.
    \end{itemize}
    
    \item \textbf{Consistent Payload Format}: All payloads are structured in a consistent data format (JSON-like structures) to ensure uniformity. Each payload includes:
    \begin{itemize}
        \item A \texttt{type} field indicating the nature of the payload (e.g., \texttt{credentials}, \texttt{query}, \texttt{request}).
        \item A \texttt{content} field containing the actual data or commands used in the attack.
    \end{itemize}
    
    \item \textbf{Realistic Sample Payloads}: The script incorporates realistic payloads for each attack type:
    \begin{itemize}
        \item \textbf{SSH brute-force}: Simulated username and password combinations commonly used in brute-force attempts.
        \item \textbf{SQL injection}: Malicious SQL queries designed to exploit database vulnerabilities.
        \item \textbf{DDoS}: Simulated high-traffic requests or packets aimed at overwhelming target services.
    \end{itemize}
    
    \item \textbf{Random Data Generation}: Each log entry includes randomized details to mimic diverse attack scenarios:
    \begin{itemize}
        \item \textbf{Source IP Addresses}: Randomly generated to represent different attack origins.
        \item \textbf{Timestamps}: Randomized within a recent time frame to reflect realistic attack timings.
        \item \textbf{Target Services}: Selected based on logical dependencies with the attack type.
    \end{itemize}
    
    \item \textbf{Data Storage}: The generated logs are saved in a JSON file format.
\end{enumerate}

\subsubsection{Tools and Technologies}

\begin{itemize}
    \item \textbf{Python}: Used for scripting the data generation process.
    \item \textbf{JSON}: Utilized for storing the synthetic logs in a structured format.
\end{itemize}

\subsubsection{Ethical Considerations}

By using synthetic data, we avoided issues related to privacy, data sensitivity, and legal restrictions~\cite{acm2018ethics}. This approach ensured compliance with ethical standards in cybersecurity research and eliminated risks associated with handling real attack data.




\subsection{Transforming Logs into STIX Format}

To integrate the synthetic honeypot logs into the Neo4j graph database using the STIX data model, it was necessary to transform the logs into the STIX 2.0 format. The Structured Threat Information Expression (STIX) is a standardized language for representing cyber threat intelligence, facilitating consistent sharing and analysis of threat data~\cite{stix2017core}.

\subsubsection{Methodology}

The transformation of synthetic honeypot logs into STIX format involved several key steps, including modifications to address specific challenges encountered during the process:

\begin{enumerate}
    \item \textbf{Parsing the Synthetic Logs}: We began by reading the JSON-formatted synthetic honeypot logs generated by our Python script. Each log entry contained fields such as \texttt{timestamp}, \texttt{source\_ip}, \texttt{attack\_type}, \texttt{target\_service}, and \texttt{payload}.

    \item \textbf{Mapping Log Fields to STIX Objects}: We established a mapping between the log fields and appropriate STIX Domain Objects (SDOs) and STIX Cyber-observable Objects (SCOs):
    \begin{itemize}
        \item \textbf{Observed Data (SDO)}: Each log entry was represented as an \texttt{ObservedData} SDO, capturing details about the observed cyber events.
        \item \textbf{Attack Pattern (SDO)}: The \texttt{attack\_type} was mapped to an \texttt{AttackPattern} SDO, referencing known patterns of malicious behavior.
        \item \textbf{Identity (SDO)}: The \texttt{source\_ip} was associated with an \texttt{Identity} SDO representing the attacker.
        \item \textbf{IPv4 Address (SCO)}: The \texttt{source\_ip} was also represented as an \texttt{IPv4Address} SCO.
        \item \textbf{Network Traffic (SCO)}: Details from the \texttt{payload} were used to create \texttt{NetworkTraffic} SCOs, encapsulating the network-related aspects of the attacks.
        \item \textbf{Artifact (SCO)}: For attacks involving a message body (e.g., SQL injection), an \texttt{Artifact} SCO was created to represent the payload content.
    \end{itemize}

    \item \textbf{Creating STIX Objects with Compliance Considerations}: Using the Python \texttt{stix2} library~\cite{stix2python}, we programmatically created STIX objects, ensuring compliance with the STIX 2.0 specification:
    \begin{itemize}
        \item \textbf{Proper Identification}: Unique identifiers were generated for each STIX object using UUIDs, adhering to the required format \texttt{<object-type>--<UUID>}.
        \item \textbf{Correct Use of Properties}: We ensured that SDOs included the \texttt{created}, \texttt{modified}, and \texttt{created\_by\_ref} properties, while SCOs did not include these properties, in compliance with the specification~\cite{stix2017core}.
        \item \textbf{Timestamp Parsing}: The \texttt{timestamp} field from the logs was parsed into \texttt{datetime} objects to satisfy the format requirements for the \texttt{first\_observed} and \texttt{last\_observed} properties in the \texttt{ObservedData} SDO.
        \item \textbf{Handling Network Traffic Properties}: The \texttt{is\_active} property in the \texttt{NetworkTraffic} SCO was explicitly set to \texttt{false} when the \texttt{end} property was present, as required.
        \item \textbf{Including Valid Hashes}: For \texttt{Artifact} SCOs representing payloads, we computed the actual SHA-256 hash of the message body content to include in the \texttt{hashes} property, ensuring validity.
    \end{itemize}

    \item \textbf{Establishing Relationships}: We defined relationships between the STIX objects to represent the associations inherent in the data:
    \begin{itemize}
        \item \texttt{ObservedData} \textbf{\textit{related-to}} \texttt{AttackPattern}
        \item \texttt{Identity (Attacker)} \textbf{\textit{uses}} \texttt{IPv4Address}
    \end{itemize}

    \item \textbf{Validating STIX Content}: We validated the created STIX objects against the STIX 2.0 specification to ensure compliance. This step was crucial for maintaining data integrity and interoperability~\cite{stix2017core}.

    \item \textbf{Exporting to JSON}: The final STIX objects were serialized into a STIX Bundle and exported to a JSON file, ready for import into the Neo4j graph database.
\end{enumerate}

\subsubsection{Modifications and Error Handling}

During the transformation process, we encountered several challenges that required modifications to the script:

\begin{itemize}
    \item \textbf{Invalid \texttt{created\_by\_ref} Values}: Initial errors arose due to invalid \texttt{created\_by\_ref} identifiers. We resolved this by creating a valid \texttt{Identity} SDO for the creator (our organization) and referencing it appropriately.
    
    \item \textbf{Timestamp Parsing Errors}: The script was updated to parse timestamp strings into \texttt{datetime} objects using the \texttt{dateutil} library~\cite{dateutil}, ensuring proper formatting for STIX properties.

    \item \textbf{Incorrect Properties in SCOs}: We removed invalid properties such as \texttt{created}, \texttt{modified}, and \texttt{created\_by\_ref} from SCOs (e.g., \texttt{NetworkTraffic}, \texttt{Artifact}, \texttt{IPv4Address}) to comply with the STIX specification.

    \item \textbf{Handling Extensions Properly}: We ensured that all required properties for extensions like \texttt{http-request-ext} were provided and only included when applicable.

    \item \textbf{Validating Hash Values}: Placeholder hash values were replaced with actual SHA-256 hashes computed from the payload content to meet the validation requirements.

    \item \textbf{Setting \texttt{is\_active} in Network Traffic}: The \texttt{is\_active} property was explicitly set to \texttt{false} when the \texttt{end} property was present in the \texttt{NetworkTraffic} SCO.
\end{itemize}

\subsubsection{Tools and Technologies}

\begin{itemize}
    \item \textbf{Python}: Used for scripting the transformation process.
    \item \textbf{\texttt{stix2} Library}: A Python library for creating and manipulating STIX 2.0 objects~\cite{stix2python}.
    \item \textbf{\texttt{dateutil} Library}: Utilized for parsing ISO 8601 date strings~\cite{dateutil}.
    \item \textbf{JSON}: Used for input and output data formats.
\end{itemize}

\subsubsection{Considerations}

Transforming the logs into STIX format required careful attention to detail to ensure that all objects were compliant with the STIX 2.0 specification. The modifications made to the script addressed validation errors and enhanced the robustness of the transformation process. This meticulous approach ensured that the data could be effectively integrated into the Neo4j graph database for further analysis.


\subsection{Loading Data into Neo4j}

To facilitate advanced graph analytics and visualization, we imported the STIX-formatted synthetic honeypot logs into a Neo4j graph database. Neo4j is a high-performance, NoSQL graph database that efficiently stores and traverses connected data~\cite{webber2012graph}. This subsection outlines the methodology used for loading the data, addressing challenges encountered during the process.

\subsubsection{Methodology}

The data import process involved the following key steps:

\begin{enumerate}
    \item \textbf{Setting Up the Neo4j Environment}:
    \begin{itemize}
        \item Installed Neo4j Desktop and ensured the database server was running locally.
        \item Installed the Neo4j Python driver (\texttt{neo4j} library) to enable interaction between Python scripts and the Neo4j database~\cite{neo4jpython}.
    \end{itemize}
    
    \item \textbf{Parsing the STIX Bundle}:
    \begin{itemize}
        \item Loaded the \texttt{honeypot\_logs\_stix.json} file using the \texttt{stix2} library~\cite{stix2python}.
        \item Parsed the STIX bundle to access individual STIX Domain Objects (SDOs) and STIX Cyber-observable Objects (SCOs).
    \end{itemize}
    
    \item \textbf{Mapping STIX Objects to Neo4j Nodes and Relationships}:
    \begin{itemize}
        \item Defined mappings where each STIX object type corresponds to a node label in Neo4j (e.g., \texttt{Identity}, \texttt{AttackPattern}, \texttt{ObservedData}).
        \item Mapped STIX relationships to Neo4j relationships, preserving the semantic meaning (e.g., \texttt{uses}, \texttt{related-to}).
    \end{itemize}
    
    \item \textbf{Creating the Data Import Script}:
    \begin{itemize}
        \item Developed a Python script utilizing the Neo4j Python driver to create nodes and relationships in the database.
        \item Implemented functions to handle each STIX object type, converting STIX objects into Neo4j-compatible formats.
    \end{itemize}
    
    \item \textbf{Handling Data Conversion and Compatibility Issues}:
    \begin{itemize}
        \item Addressed challenges related to data type compatibility between STIX objects and Neo4j properties.
        \item Implemented a \texttt{flatten\_dict} function to flatten nested dictionaries and exclude unsupported data types.
    \end{itemize}
    
    \item \textbf{Executing the Script and Verifying Data Import}:
    \begin{itemize}
        \item Ran the script to import the data into Neo4j.
        \item Verified the successful import by querying the database using Cypher queries and visualizing the graph structure.
    \end{itemize}
\end{enumerate}

\subsubsection{Challenges and Solutions}

During the data import process, several challenges were encountered:

\begin{itemize}
    \item \textbf{Unsupported Data Types}:
    \begin{itemize}
        \item \textit{Issue}: The Neo4j driver does not support custom objects or certain complex data types (e.g., nested dictionaries, lists of dictionaries).
        \item \textit{Solution}: Converted STIX objects to dictionaries using \texttt{json.loads(obj.serialize())}. Flattened nested dictionaries to ensure all properties were of supported data types (strings, numbers, booleans, lists).
    \end{itemize}
    
    \item \textbf{Missing Methods in STIX2 Library}:
    \begin{itemize}
        \item \textit{Issue}: Methods like \texttt{to\_dict()} and \texttt{as\_dict()} were not available in the version of the \texttt{stix2} library used.
        \item \textit{Solution}: Utilized \texttt{json.loads(obj.serialize())} to obtain a dictionary representation of STIX objects, ensuring compatibility across different library versions~\cite{stix2python}.
    \end{itemize}
    
    \item \textbf{Attribute Errors}:
    \begin{itemize}
        \item \textit{Issue}: Encountered \texttt{AttributeError} exceptions when accessing certain attributes or methods of STIX objects.
        \item \textit{Solution}: Adjusted the code to use methods and attributes consistent with the library version. Added checks and exception handling to manage potential discrepancies.
    \end{itemize}
    
    \item \textbf{Flattening Nested Structures}:
    \begin{itemize}
        \item \textit{Issue}: Nested dictionaries within STIX objects led to properties that Neo4j could not store directly.
        \item \textit{Solution}: Implemented a recursive \texttt{flatten\_dict} function to flatten nested structures. Excluded keys that were not essential or could cause issues (e.g., \texttt{extensions}, \texttt{objects}).
    \end{itemize}
\end{itemize}

\subsubsection{Tools and Technologies}

\begin{itemize}
    \item \textbf{Neo4j Graph Database}: Used for storing and querying graph data~\cite{neo4j}.
    \item \textbf{Neo4j Python Driver}: Facilitated interaction with the Neo4j database from Python scripts~\cite{neo4jpython}.
    \item \textbf{Python}: Used for scripting the data import process.
    \item \textbf{\texttt{stix2} Library}: Utilized for parsing and handling STIX 2.0 objects~\cite{stix2python}.
    \item \textbf{Cypher Query Language}: Employed for querying the Neo4j database~\cite{francis2018cypher}.
\end{itemize}

\subsubsection{Considerations}

The process of importing STIX-formatted data into Neo4j required careful handling of data types and structures to ensure compatibility. By systematically addressing the challenges and adapting the code accordingly, we successfully loaded the data into the graph database. This setup enables sophisticated graph analytics and visualization of cyber threat intelligence data, enhancing our ability to detect and analyze attack patterns.




\section{Conclusion and Future Work}

In this study, we successfully transformed synthetic honeypot logs into the Structured Threat Information Expression (STIX) 2.0 format and imported them into a Neo4j graph database. This process involved generating synthetic logs, transforming them into STIX objects, and addressing various challenges during data import.

\subsection{Summary of Contributions}

\begin{itemize}
    \item \textbf{Synthetic Log Generation}: Developed a Python script to generate synthetic honeypot logs simulating different attack types, including DDoS attacks, SQL injection, and SSH brute-force attempts.
    \item \textbf{Transformation to STIX Format}: Created a script to convert the synthetic logs into STIX 2.0 objects, ensuring compliance with the STIX specification~\cite{stix2017core}.
    \item \textbf{Data Import into Neo4j}: Imported the STIX-formatted data into Neo4j, mapping STIX objects to nodes and relationships in the graph database~\cite{webber2012graph}.
    \item \textbf{Handling Data Compatibility Issues}: Addressed challenges related to data type compatibility and property constraints in Neo4j by flattening nested structures.
\end{itemize}

\subsection{Simplifying Nested Structures}

One of the significant challenges encountered was handling the nested structures inherent in STIX objects. Neo4j properties are limited to simple data types (strings, numbers, booleans, and lists of these types) and do not support nested dictionaries or complex data structures~\cite{neo4j}. To overcome this limitation, we implemented a \textit{flattening} process:

\begin{itemize}
    \item \textbf{Flattening Nested Dictionaries}: Transformed nested dictionaries into a single-level dictionary by concatenating keys with an underscore separator. For example, a nested property like \texttt{address\{city\}} becomes \texttt{address\_city}.
    \item \textbf{Excluding Unsupported Fields}: Identified and excluded fields that could not be flattened effectively or were not essential for analysis, such as large binary data or deeply nested extensions.
    \item \textbf{Including Payload Data}: Adjusted the flattening function to include critical fields like \texttt{extensions} when necessary, ensuring that important data like attack payloads were not omitted from the graph database.
\end{itemize}

This approach allowed us to maintain data integrity and include essential information in Neo4j while adhering to its property constraints.

\subsection{Limitations}

Despite the successful import of data, certain limitations were identified:

\begin{itemize}
    \item \textbf{Data Loss During Flattening}: The flattening process may lead to data loss or oversimplification of complex structures, potentially impacting the depth of analysis.
    \item \textbf{Property Size Constraints}: Neo4j imposes size limits on property values, which may restrict the storage of large payloads or detailed metadata.
    \item \textbf{Security Considerations}: Storing sensitive payload data within the graph database raises concerns about data privacy and security, necessitating careful handling and access control.
\end{itemize}

\subsection{Future Work}

Building upon the foundation established in this study, future work can explore the following areas:

\begin{itemize}
    \item \textbf{Enhanced Data Modeling}: Develop a more sophisticated data model that better represents the relationships and hierarchies within the STIX data, potentially using advanced features of Neo4j or alternative graph databases.
    \item \textbf{Integration with Real-world Data}: Apply the transformation and import process to real honeypot logs to validate the approach and uncover practical challenges.
    \item \textbf{Visualization and Analysis Tools}: Implement visualization tools and analytical queries to leverage the graph structure for threat intelligence insights and anomaly detection~\cite{barnum2014standardizing}.
    \item \textbf{Security and Access Control}: Incorporate security measures to protect sensitive data within the database, such as role-based access control and data encryption.
    \item \textbf{Performance Optimization}: Investigate methods to optimize the import process and query performance, especially with larger datasets.
\end{itemize}

\subsection{Conclusion}

This study demonstrated a practical approach to transforming synthetic honeypot logs into the STIX format and importing them into a graph database for advanced analysis. By addressing challenges related to data compatibility and structure, we enabled the integration of cyber threat intelligence data into a format suitable for graph-based exploration. The methodologies and solutions presented provide a foundation for further research and development in the field of cybersecurity analytics.


\bibliographystyle{IEEEtran}
\bibliography{references}

\end{document}
